======================================================
Unity ML-Agents 적용을 위한 개발 문서 (Stage 1)
======================================================

1. 개요 및 목표
------------------------------------------------------
본 문서는 타워 디펜스 프로젝트에 Unity ML-Agents를 도입하여, AI 에이전트가 스스로 게임을 플레이하고 학습하는 환경을 구축하기 위한 개발 가이드를 제공합니다.


1.1. 시뮬레이션 상세 목표 (Stage 1 검증)

AI 학습을 통해 아래의 목표를 달성하는 최적의 게임 밸런스 파라미터를 찾는 것을 목표로 합니다.

- 성공률: AI 에이전트의 스테이지 클리어 성공률 90% 이상 달성
- 플레이 시간: 평균 플레이 시간이 약 300초(5분) 내외로 수렴하도록 유도
- 타워 사용 유도: 2가지 종류의 타워(예: 기본 포탑, 슬로우 타워)가 모두 특정 상황에서 필요하도록 구조 설계
- 전략적 딜레마 부여: 한정된 재화 내에서 '기존 타워 업그레이드'와 '새로운 타워 건설' 사이에서 AI가 전략적인 고민을 하도록 유도


1.2. AI가 최적화할 주요 변수

시뮬레이션 과정에서 AI는 다음 변수들을 조정하며 최적의 값을 탐색하게 됩니다.
(주: 초기 단계에서는 개발자가 변수 범위를 설정하고, AI는 해당 범위 내에서 행동 패턴을 최적화합니다.)

- 빌드 노드: 최적의 빌드 노드 위치, 효과적인 빌드 노드 개수
- 웨이브: 전체 웨이브 수, 웨이브 별 적 유닛 구성
- 타워 스탯: 타워의 공격력, 비용, 업그레이드 효율
- 에너미 스탯: 에너미의 체력, 이동 속도, 웨이브 당 출현 수


2. 사전 준비 및 환경 설정
------------------------------------------------------
- Unity ML-Agents 패키지 설치 (com.unity.ml-agents)
- Python 3.9+ 및 관련 패키지 설치 (pip install mlagents torch)
- 설치 확인: 터미널에서 `mlagents-learn --help` 명령어 실행


3. 주요 구현 요소 (개발 요청사항)
------------------------------------------------------

3.1. 에이전트 (Agent) 생성
- `TowerDefenseAgent.cs` 스크립트 생성 (Agent 클래스 상속)
- 씬에 빈 오브젝트를 만들고 위 스크립트 부착

3.2. 관찰 (Observations) - AI의 '눈'
- 현재 보유 재화, 현재 웨이브, 남은 생명력
- 각 빌드 노드의 상태 (비어있음/타워 종류 ID)
- 접근 중인 적 유닛들의 정보 (종류, 수, 주요 경로 위치 등)

3.3. 행동 (Actions) - AI의 '손과 발'
- 이산 행동(Discrete Actions) 방식 사용
- Branch 1 (행동 종류): 타워 건설 / 타워 업그레이드 / 대기
- Branch 2 (타워 종류): 기본 포탑 / 슬로우 타워
- Branch 3 (행동 위치): N개의 빌드 노드 중 선택

3.4. 보상 (Rewards) - AI의 '동기부여'
- 긍정적 보상 (+):
  * 적 유닛 처치 (+0.1)
  * 웨이브 클리어 (+1.0)
- 부정적 보상 (-):
  * 생명력 감소 (-0.2)
  * 게임 패배 (-1.0 및 에피소드 종료)
  * 불가능한 행동 시도 (재화 부족 등) (-0.05)
- (중요) 업그레이드/신규 건설 딜레마 부여:
  * 업그레이드된 타워로만 효율적으로 처치할 수 있는 강력한 적 유닛에게 높은 보상(+0.3 등)을 책정하여, '신규 타워'와 '기존 타워 업그레이드' 사이의 판단을 유도합니다.


4. 훈련 프로세스
------------------------------------------------------
1. 훈련 설정 파일 `td_config.yaml` 작성
2. 터미널에서 `mlagents-learn config/td_config.yaml --run-id=TowerDefense_Stage1_Run_1` 실행
3. Unity 에디터에서 Play 버튼을 눌러 훈련 시작
4. 터미널에서 `tensorboard --logdir results`로 훈련 과정 모니터링


5. 기대 결과물
------------------------------------------------------
- 목표(1.1)를 달성하는 플레이 패턴을 보여주는 훈련된 모델 파일 (`.onnx`).
- TensorBoard 상에서 누적 보상이 안정적으로 상승하여 수렴하는 그래프.
- AI의 플레이를 통해 검증된 최적의 게임 밸런스 파라미터 리포트.


6. 추가 고려사항 및 심화 과정
------------------------------------------------------
- 맵 레이아웃 최적화 (고급): 빌드 노드의 위치나 개수를 AI가 직접 찾게 하는 것은 PCGRL(절차적 콘텐츠 생성) 영역에 해당하며, 초기 구현 이후에 시도해볼 수 있는 심화 과제입니다. 초기 단계에서는 몇 가지 맵 프리셋을 두고 어떤 프리셋이 목표 달성에 유리한지 분석하는 방식으로 접근합니다.